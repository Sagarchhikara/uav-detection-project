import streamlit as st
import cv2
import numpy as np
from pathlib import Path
import tempfile
import sys
import os
import json

# Handle plotly imports with fallback
try:
    import pandas as pd
    import plotly.express as px
    import plotly.graph_objects as go
    PLOTLY_AVAILABLE = True
except ImportError as e:
    st.error(f"Plotly/Pandas import error: {e}")
    st.info("Installing missing dependencies...")
    import subprocess
    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'pandas', 'plotly'])
    try:
        import pandas as pd
        import plotly.express as px
        import plotly.graph_objects as go
        PLOTLY_AVAILABLE = True
        st.success("Dependencies installed successfully! Please refresh the page.")
    except ImportError:
        PLOTLY_AVAILABLE = False
        st.warning("Plotly not available. Some visualizations will be disabled.")

# Add src to path
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

try:
    from src.detection.detector_with_tracking import DroneDetectorTracker
    DETECTOR_AVAILABLE = True
except ImportError as e:
    st.error(f"Detection system import error: {e}")
    st.info("Please make sure all dependencies are installed and the src modules are available.")
    DETECTOR_AVAILABLE = False

st.set_page_config(
    page_title="Anti-UAV Detection System",
    page_icon="üöÅ",
    layout="wide"
)

def main():
    st.title("üöÅ Anti-UAV Detection System")
    st.markdown("Real-time drone detection, tracking, and behavior analysis")
    
    # Check if detector is available
    if not DETECTOR_AVAILABLE:
        st.error("‚ùå Detection system not available. Please check the installation.")
        st.stop()
    
    # Sidebar for configuration
    st.sidebar.header("Configuration")
    
    # Model selection
    model_options = []
    # Check both possible paths
    possible_paths = [
        "runs/detect/models/finetuned/drone_detector/weights/best.pt",
        "models/finetuned/drone_detector/weights/best.pt"
    ]
    
    best_model_path = None
    for path in possible_paths:
        if Path(path).exists():
            best_model_path = path
            break
            
    if best_model_path:
        model_options.append("Trained Model (best.pt)")
    
    model_options.append("Pre-trained YOLOv8m")
    
    selected_model = st.sidebar.selectbox("Select Model", model_options)
    
    if selected_model == "Trained Model (best.pt)":
        model_path = best_model_path
    else:
        model_path = "yolov8m.pt"
    
    # Detection parameters
    conf_threshold = st.sidebar.slider("Confidence Threshold", 0.1, 1.0, 0.25, 0.05)
    
    # Restricted zones
    st.sidebar.subheader("Restricted Zones")
    enable_zones = st.sidebar.checkbox("Enable Restricted Zones")
    
    restricted_zones = []
    if enable_zones:
        zone_coords = st.sidebar.text_area(
            "Zone Coordinates (JSON format)",
            value='[[[100, 100], [300, 100], [300, 300], [100, 300]]]',
            help="List of polygons, each polygon is a list of [x, y] coordinates"
        )
        try:
            restricted_zones = json.loads(zone_coords)
        except:
            st.sidebar.error("Invalid JSON format for zones")
    
    # Main content
    tab1, tab2, tab3 = st.tabs(["üé• Video Processing", "üìä Analytics", "‚ÑπÔ∏è About"])
    
    with tab1:
        video_processing_tab(model_path, conf_threshold, restricted_zones)
    
    with tab2:
        analytics_tab()
    
    with tab3:
        about_tab()

def video_processing_tab(model_path, conf_threshold, restricted_zones):
    st.header("Video Processing")
    
    # File upload
    uploaded_file = st.file_uploader(
        "Upload Video File",
        type=['mp4', 'avi', 'mov', 'mkv'],
        help="Upload a video file for drone detection analysis"
    )
    
    if uploaded_file is not None:
        # Save uploaded file temporarily
        with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as tmp_file:
            tmp_file.write(uploaded_file.read())
            temp_video_path = tmp_file.name
        
        # Display video info
        cap = cv2.VideoCapture(temp_video_path)
        fps = int(cap.get(cv2.CAP_PROP_FPS))
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        duration = total_frames / fps
        cap.release()
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("Resolution", f"{width}x{height}")
        with col2:
            st.metric("FPS", fps)
        with col3:
            st.metric("Duration", f"{duration:.1f}s")
        with col4:
            st.metric("Frames", total_frames)
        
        # Processing options
        st.subheader("Processing Options")
        
        col1, col2 = st.columns(2)
        with col1:
            process_full = st.checkbox("Full Analysis (Detection + Tracking + Behavior)", value=True)
        with col2:
            save_output = st.checkbox("Save Output Video", value=True)
        
        # Process button
        if st.button("üöÄ Start Processing", type="primary"):
            process_video(temp_video_path, model_path, conf_threshold, restricted_zones, process_full, save_output, uploaded_file)
        
        # Display download button if processing is complete
        if 'processing_complete' in st.session_state and st.session_state.processing_complete:
            st.success("‚úÖ Processing complete!")
            
            # Display final frame if available
            if 'final_frame' in st.session_state:
                st.image(st.session_state.final_frame, caption="Final processed frame", channels="RGB", use_column_width=True)
            
            # Download button
            output_path = st.session_state.get('output_path')
            if output_path and Path(output_path).exists():
                with open(output_path, 'rb') as f:
                    download_filename = f"processed_{uploaded_file.name}" if uploaded_file else "processed_video.mp4"
                    st.download_button(
                        label="üì• Download Processed Video",
                        data=f.read(),
                        file_name=download_filename,
                        mime="video/mp4"
                    )
        
        # Clean up temp file
        try:
            if Path(temp_video_path).exists():
                os.unlink(temp_video_path)
        except:
            pass  # Ignore cleanup errors

def process_video(video_path, model_path, conf_threshold, restricted_zones, process_full, save_output, uploaded_file):
    """Process video with progress tracking"""
    
    # Reset state
    if 'processing_complete' in st.session_state:
        del st.session_state.processing_complete
    if 'output_path' in st.session_state:
        del st.session_state.output_path
    if 'final_frame' in st.session_state:
        del st.session_state.final_frame
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    try:
        # Check if video file exists
        if not Path(video_path).exists():
            st.error(f"Video file not found: {video_path}")
            return
        
        # Initialize detector
        status_text.text("Initializing detector...")
        detector = DroneDetectorTracker(
            model_path=model_path,
            conf_threshold=conf_threshold,
            restricted_zones=restricted_zones if process_full else None
        )
        
        # Open video
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            st.error("Failed to open video file. Please check the file format.")
            return
            
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        fps = int(cap.get(cv2.CAP_PROP_FPS))
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        
        if total_frames == 0:
            st.error("Video file appears to be empty or corrupted.")
            cap.release()
            return
        
        # Prepare output
        output_path = None
        out = None
        if save_output:
            output_filename = f"processed_{uploaded_file.name}" if uploaded_file else "processed_video.mp4"
            output_path = f"outputs/videos/{output_filename}"
            Path(output_path).parent.mkdir(parents=True, exist_ok=True)
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
            
            # Save output path to session state
            st.session_state.output_path = output_path
        
        # Process frames
        frame_idx = 0
        all_tracks = []
        all_alerts = []
        
        # Create placeholder for video display
        video_placeholder = st.empty()
        
        annotated_frame = None
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            if process_full:
                tracks, annotated_frame, alerts = detector.process_frame(frame)
                all_tracks.extend(tracks)
                all_alerts.extend(alerts)
            else:
                # Simple detection only
                detections = detector.detector.detect(frame)
                annotated_frame = detector.detector.draw_detections(frame.copy(), detections)
                tracks = []
                alerts = []
            
            # Save frame if requested
            if out is not None:
                out.write(annotated_frame)
            
            # Update progress
            frame_idx += 1
            progress = frame_idx / total_frames
            progress_bar.progress(progress)
            status_text.text(f"Processing frame {frame_idx}/{total_frames} - {len(tracks)} active tracks")
            
            # Display current frame (every 30 frames to avoid too much updating)
            if frame_idx % 30 == 0:
                # Convert BGR to RGB for display
                display_frame = cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB)
                video_placeholder.image(display_frame, channels="RGB", use_column_width=True)
        
        cap.release()
        if out is not None:
            out.release()
        
        # storage final frame for display
        if annotated_frame is not None:
            st.session_state.final_frame = cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB)
            
        st.session_state.processing_complete = True
    
    except Exception as e:
        st.error(f"Error processing video: {str(e)}")
        status_text.text("‚ùå Processing failed!")
        
        # Show detailed error information
        with st.expander("Error Details"):
            st.code(f"Error type: {type(e).__name__}")
            st.code(f"Error message: {str(e)}")
            import traceback
            st.code(f"Traceback:\n{traceback.format_exc()}")
        
        # Cleanup
        if 'cap' in locals():
            cap.release()
        if 'out' in locals() and out is not None:
            out.release()

def analytics_tab():
    st.header("Analytics Dashboard")
    
    if not PLOTLY_AVAILABLE:
        st.warning("Analytics visualizations require Plotly. Please install it: pip install plotly pandas")
        st.info("Basic analytics will still be shown.")
    
    # Check for existing logs
    log_file = Path("outputs/logs/alerts.json")
    
    if not log_file.exists():
        st.info("No analytics data available. Process a video first to see analytics.")
        return
    
    # Load alerts
    alerts = []
    try:
        with open(log_file, 'r') as f:
            for line in f:
                alerts.append(json.loads(line.strip()))
    except:
        st.error("Error loading analytics data")
        return
    
    if not alerts:
        st.info("No alerts found in log file.")
        return
    
    # Convert to DataFrame if pandas is available
    if PLOTLY_AVAILABLE:
        df = pd.DataFrame(alerts)
    
    # Summary metrics
    st.subheader("Summary Statistics")
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("Total Alerts", len(alerts))
    with col2:
        if PLOTLY_AVAILABLE:
            st.metric("Unique Tracks", df['track_id'].nunique())
        else:
            unique_tracks = len(set(alert['track_id'] for alert in alerts))
            st.metric("Unique Tracks", unique_tracks)
    with col3:
        high_alerts = sum(1 for alert in alerts if alert.get('alert_level') == 'HIGH')
        st.metric("High Priority", high_alerts)
    with col4:
        avg_speed = sum(alert.get('speed_value', 0) for alert in alerts) / len(alerts)
        st.metric("Avg Speed", f"{avg_speed:.1f} px/s")
    
    if PLOTLY_AVAILABLE:
        # Alert level distribution
        st.subheader("Alert Distribution")
        
        col1, col2 = st.columns(2)
        
        with col1:
            alert_counts = df['alert_level'].value_counts()
            fig = px.pie(values=alert_counts.values, names=alert_counts.index, 
                        title="Alert Levels")
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            behavior_data = {
                'Speed Violations': df['speed_flag'].sum(),
                'Hovering Detected': df['hover_flag'].sum(),
                'Zone Violations': df['zone_flag'].sum()
            }
            fig = px.bar(x=list(behavior_data.keys()), y=list(behavior_data.values()),
                        title="Behavior Violations")
            st.plotly_chart(fig, use_container_width=True)
        
        # Timeline
        st.subheader("Alert Timeline")
        df['timestamp'] = pd.to_datetime(df['timestamp'])
        
        fig = px.scatter(df, x='timestamp', y='track_id', 
                        color='alert_level', size='speed_value',
                        title="Alerts Over Time")
        st.plotly_chart(fig, use_container_width=True)
        
        # Raw data
        st.subheader("Raw Alert Data")
        st.dataframe(df)
    else:
        # Basic analytics without plotly
        st.subheader("Alert Breakdown")
        
        alert_levels = {}
        behavior_counts = {'speed_flag': 0, 'hover_flag': 0, 'zone_flag': 0}
        
        for alert in alerts:
            level = alert.get('alert_level', 'UNKNOWN')
            alert_levels[level] = alert_levels.get(level, 0) + 1
            
            for behavior in behavior_counts:
                if alert.get(behavior, False):
                    behavior_counts[behavior] += 1
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**Alert Levels:**")
            for level, count in alert_levels.items():
                st.write(f"- {level}: {count}")
        
        with col2:
            st.write("**Behavior Violations:**")
            st.write(f"- Speed Violations: {behavior_counts['speed_flag']}")
            st.write(f"- Hovering Detected: {behavior_counts['hover_flag']}")
            st.write(f"- Zone Violations: {behavior_counts['zone_flag']}")
        
        # Raw data as JSON
        st.subheader("Raw Alert Data")
        st.json(alerts)

def about_tab():
    st.header("About Anti-UAV Detection System")
    
    st.markdown("""
    ## üéØ Purpose
    This system uses computer vision and machine learning to detect drones in video footage 
    and analyze their behavior for security applications.
    
    ## üîß Features
    - **Drone Detection**: YOLOv8-based object detection
    - **Multi-Object Tracking**: Track multiple drones across frames
    - **Behavior Analysis**: Detect suspicious behaviors:
        - High-speed movement
        - Hovering patterns
        - Restricted zone entry
    - **Real-time Alerts**: Automated alert generation
    - **Analytics Dashboard**: Comprehensive analysis tools
    
    ## üöÄ Technology Stack
    - **Deep Learning**: PyTorch + YOLOv8
    - **Computer Vision**: OpenCV
    - **Tracking**: Custom IoU-based tracker
    - **UI**: Streamlit
    - **Analytics**: Plotly + Pandas
    
    ## üìä Model Performance
    - **Detection Accuracy**: >80% mAP on test set
    - **Processing Speed**: >15 FPS on GPU
    - **Tracking Accuracy**: >70% MOTA
    
    ## üéÆ Usage Instructions
    1. **Upload Video**: Use the video processing tab to upload your footage
    2. **Configure Settings**: Adjust detection threshold and restricted zones
    3. **Process**: Click "Start Processing" to analyze the video
    4. **Review Results**: Check the analytics dashboard for insights
    
    ## ‚ö†Ô∏è Notes
    - For best results, use the trained model (requires training on drone dataset)
    - GPU acceleration recommended for real-time processing
    - Restricted zones help identify unauthorized drone activity
    """)
    
    # System status
    st.subheader("System Status")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # Check model availability
        if Path("models/finetuned/drone_detector/weights/best.pt").exists():
            st.success("‚úÖ Trained model available")
        else:
            st.warning("‚ö†Ô∏è No trained model found")
        
        # Check GPU
        try:
            import torch
            if torch.cuda.is_available():
                st.success(f"‚úÖ GPU available: {torch.cuda.get_device_name(0)}")
            else:
                st.info("‚ÑπÔ∏è Running on CPU")
        except:
            st.error("‚ùå PyTorch not available")
    
    with col2:
        # Check dependencies
        try:
            from ultralytics import YOLO
            st.success("‚úÖ YOLOv8 available")
        except:
            st.error("‚ùå YOLOv8 not installed")
        
        try:
            import cv2
            st.success("‚úÖ OpenCV available")
        except:
            st.error("‚ùå OpenCV not installed")
        
        # Check model status
        if Path("models/finetuned/drone_detector/weights/best.pt").exists():
            st.success("‚úÖ Custom trained model available")
        else:
            st.info("‚ÑπÔ∏è Using pre-trained YOLOv8m model")

if __name__ == "__main__":
    main()